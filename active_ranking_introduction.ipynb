{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Ranking from Pairwise Comparisons and when Parametric Assumptions Donâ€™t Help\n",
    "\n",
    "We consider sequential or active ranking of a set of n items based on noisy pairwise compar- isons. Items are ranked according to the probability that a given item beats a randomly chosen item, and ranking refers to partitioning the items into sets of pre-specified sizes according to their scores. This notion of ranking includes as special cases the identification of the top-$k$ items and the total ordering of the items. For simplicity, let us consider the top-$k$ identification problem.\n",
    "\n",
    "We consider a collection of $n$ items, and our data consists\n",
    "of outcomes of comparisons between pairs of items in this collection\n",
    "that are collected in a sequential fashion, also known as the active\n",
    "setting. We assume that the outcomes of comparisons are\n",
    "stochastic---that is, item $i$ beats item $j$ with an unknown\n",
    "probability $M_{ij} \\in (0,1)$. The outcomes of pairwise\n",
    "comparisons are furthermore assumed to be statistically mutually\n",
    "independent. We define the ordering of the items in terms of their\n",
    "(unknown) scores, where the score $\\tau_i$ of item $i$ is defined as\n",
    "the probability that item $i$ beats an item chosen uniformly at random\n",
    "from all other items:\n",
    "$$\n",
    "\\tau_i := \\frac{1}{n - 1} \\sum_{j\\neq i} M_{ij}.\n",
    "$$\n",
    "Assuming that the scores are all distinct, they define a unique ranking of the $n$ items. Identifying the top-$k$ items amounts to identify two disjoint subsets $\\hat S_1, \\hat S_2 \\subset \\{1,\\ldots,n\\}$ such that all items in $\\hat S_1$ have a larger score than the items in the set $\\hat S_2$. \n",
    "\n",
    "An active ranking algorithm acts on a pairwise comparison model $M$. The goal is to identify the top-$k$ items from active comparisons.  At each time\n",
    "instant, the algorithm can compare two arbitrary items, and the choice\n",
    "of which items to compare may be based on the outcomes of previous\n",
    "comparisons. As a result of comparing two items $i$ and $j$, the\n",
    "algorithm receives an independent draw of a binary random variable\n",
    "with success probability $M_{ij}$ in response.  After termination\n",
    "dictated by an associated stopping rule, the algorithm returns a\n",
    "ranking $\\hat S_1, \\hat S_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "We start with defining a class for representing a pairwise comparision model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class pairwise:\n",
    "    def __init__(self,n):\n",
    "        self.ctr = 0 # counts how many comparisons have been queried from the model\n",
    "        self.n = n \n",
    "\n",
    "    def sortP(self): # sort the comparison matrix according to scores\n",
    "        scores = self.scores()\n",
    "        pi = argsort(-scores)\n",
    "        self.P = self.P[:,pi]\n",
    "        self.P = self.P[pi,:]\n",
    "    \n",
    "    def generate_deterministic_BTL(self,w): # generates a Bradley-Terry-Luce model\n",
    "        self.w = w\n",
    "        self.P = zeros((self.n,self.n))\n",
    "        for i in range(self.n):\n",
    "            for j in range(i,self.n):\n",
    "                self.P[i,j] = 1/( 1 + exp( w[j] - w[i] ) )\n",
    "                self.P[j,i] = 1 - self.P[i,j]\n",
    "        self.sortP()\n",
    "\n",
    "    def compare(self,i,j): # draw a comparision from the model\n",
    "        if i == j:\n",
    "            print(\"does not make sense\")\n",
    "        self.ctr += 1\n",
    "        if random.rand() < self.P[i,j]:\n",
    "            return 1 # i beats j\n",
    "        else:\n",
    "            return 0 # j beats i\n",
    "\n",
    "    def scores(self):\n",
    "        P = array(self.P)\n",
    "        for i in range(len(P)):\n",
    "            P[i,i] = 0\n",
    "        return sum(P,axis=1)/(self.n-1)\n",
    "    \n",
    "    def topk_complexity(self,k=1):\n",
    "        sc = self.scores();\n",
    "        lower = sum([ 1/(sc[k-1]-sc[i])**2 for i in range(k,self.n)])\n",
    "        upper = sum([ 1/(sc[i]-sc[k])**2 for i in range(0,k)])\n",
    "        return lower + upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us next generate a small BTL model, and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pairwise comparison probabilities are:\n",
      " [[ 0.5         0.549834    0.59868766  0.64565631  0.68997448]\n",
      " [ 0.450166    0.5         0.549834    0.59868766  0.64565631]\n",
      " [ 0.40131234  0.450166    0.5         0.549834    0.59868766]\n",
      " [ 0.35434369  0.40131234  0.450166    0.5         0.549834  ]\n",
      " [ 0.31002552  0.35434369  0.40131234  0.450166    0.5       ]] \n",
      "\n",
      "The scores of the items are:\n",
      " [ 0.62103811  0.56108599  0.5         0.43891401  0.37896189] \n",
      "\n",
      "Comparing 1 to 2 gives: 2 wins\n",
      "Comparing 1 to 2 gives: 1 wins\n",
      "Comparing 1 to 2 gives: 1 wins\n",
      "Comparing 1 to 2 gives: 2 wins\n",
      "Comparing 1 to 2 gives: 2 wins\n",
      "5  queries have been made\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "delta = 0.1\n",
    "pmodel = pairwise(n)\n",
    "pmodel.generate_deterministic_BTL([ i/float(n) for i in range(n) ])\n",
    "\n",
    "print(\"The pairwise comparison probabilities are:\\n\", pmodel.P, \"\\n\")\n",
    "\n",
    "print(\"The scores of the items are:\\n\", pmodel.scores(),\"\\n\")\n",
    "\n",
    "# make a few comparisions\n",
    "for i in range(5): \n",
    "    print(\"Comparing 1 to 2 gives:\", '1 wins' if pmodel.compare(1,2) else '2 wins')\n",
    "    \n",
    "print(pmodel.ctr, \" queries have been made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ranking algorithm\n",
    "Let us next implement the randing algorithm. The algorithm in our paper uses an elimination strategy - below we implement a variant of our algorithm that is based on the LUCB (lower upper confidence bound) strategy from the bandit literature. Both algorithms share the same guarantees on the sample complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LUCB_ranking:\n",
    "    def __init__(self,pairwise,k):\n",
    "        self.k = k\n",
    "        self.pairwise = pairwise # instance of pairwise\n",
    "        self.pairwise.ctr = 0 # number of random comparisons made\n",
    "\n",
    "    def random_cmp(self,i): # compare i to randomly choosen other item\n",
    "        j = random.choice(range(self.pairwise.n-1))\n",
    "        if j >= i:\n",
    "            j += 1\n",
    "        return float( self.pairwise.compare(i,j) )\n",
    "\n",
    "    def alpha(self,Ti): # confidence interval\n",
    "        n = self.pairwise.n\n",
    "        beta = log(n/self.delta) + 0.75*log(log(n/self.delta)) + 1.5*log(1+log(Ti/2))\n",
    "        return sqrt( 3 / (2*Ti) ) \n",
    "\n",
    "    def rank(self,delta=0.1,numit = 6000000):\n",
    "        self.delta = delta\n",
    "        S = [] # list with entries ( i, T_i, scorehat_i, scorehat_i - alpha_i, scorehat_i + alpha_i, alpha_i)\n",
    "        # compare each item once to initialize\n",
    "        for i in range(self.pairwise.n):\n",
    "            scorehat = self.random_cmp(i)\n",
    "            S.append( ( i, 1, scorehat, scorehat-self.alpha(1), scorehat+self.alpha(1), self.alpha(1) ) )\n",
    "            \n",
    "        for iit in range(numit):\n",
    "            # sort descending by score ('entry' has fields (i, T_i, scorehat_i,...)\n",
    "            S = sorted(S , key=lambda entry: entry[2],reverse=True)\n",
    "            # min scorehat_i - alpha_i; min over (1),...,(k)\n",
    "            d1low = min( S[:self.k] , key=lambda entry: entry[3] )\n",
    "            # max scorehat_i + alpha_i; max over (k+1),...,(n)\n",
    "            d2up = max( S[self.k:] , key=lambda entry: entry[4] )\n",
    "\n",
    "            if d1low[3] > d2up[4]: # termination condition\n",
    "                break # terminate\n",
    "\n",
    "            for it in [d1low,d2up]: # items to sample in next round\n",
    "                Ti = it[1] + 1\n",
    "                shat = 1.0/Ti*( (Ti-1)*it[2] + self.random_cmp( it[0] ) )\n",
    "                alphai = self.alpha(Ti)\n",
    "                S[S.index(it)] = ( it[0], Ti, shat, shat - alphai, shat + alphai, alphai )\n",
    "        self.S = S\n",
    "        estimated_ranking = [s[0] for s in S]\n",
    "        self.ranking = [ estimated_ranking[:self.k], estimated_ranking[self.k:]  ]\n",
    "\n",
    "    def plot_scores(self): # plot \n",
    "        n = len(self.S)\n",
    "        scorehat = [self.S[i][2] for i in range(n)]\n",
    "        upperest = [self.S[i][3] for i in range(n)]\n",
    "        lowerest = [self.S[i][4] for i in range(n)]\n",
    "        plt.plot(range(n),scorehat, 'rx',range(n),upperest, 'bx',range(n),lowerest, 'yx' )\n",
    "        plt.show()\n",
    "        \n",
    "    def evaluate_perfect_recovery(self): # did it suceed?\n",
    "        return set(self.ranking[0]) == set([i for i in range(self.k)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the algorithm on our example, for $k=2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top-k items are:  [0, 1]\n",
      "The algorithm did succeed :)\n",
      "It required  1939  many comparisons.\n",
      "\n",
      "Confidence intervals at termination (red is the estimate, yellow and blue are the lower and upper confidence bounds):\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7gCQoP8HjcHK+Wn00KsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109e6ac88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 2\n",
    "delta = 0.1\n",
    "alg = LUCB_ranking(pmodel,k)\n",
    "alg.rank(0.1)\n",
    "print(\"The top-k items are: \", alg.ranking[0])\n",
    "print(\"The algorithm did\", \"succeed :)\" if alg.evaluate_perfect_recovery() else \"not succeed :(\")\n",
    "print(\"It required \", alg.pairwise.ctr, \" many comparisons.\\n\")\n",
    "print(\"Confidence intervals at termination (red is the estimate, yellow and blue are the lower and upper confidence bounds):\")\n",
    "alg.plot_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The theory\n",
    "\n",
    "Accordign to our theory, the sample complexity for scores \n",
    "$\\tau_1 > \\tau_2 > \\ldots \\tau_n$ \n",
    "is (up to log-factors) given by:\n",
    "$$\n",
    "H(M) = \\sum_{i=1}^k \\frac{1}{(\\tau_i - \\tau_{k+1})^2}\n",
    "+\n",
    "\\sum_{i=k+1}^{n} \\frac{1}{(\\tau_k - \\tau_{i})^2}.\n",
    "$$\n",
    "Let's verify this with a simple experiment. We generate models with different parameters, and see whether the ratio of the empirical sample complexity over $H(M)$ is approximately constant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(M):  364.060505465\n",
      "empirical sample complexity / H(M): 4.50254827258 \n",
      "\n",
      "H(M):  671.914678452\n",
      "empirical sample complexity / H(M): 4.73512501219 \n",
      "\n",
      "H(M):  1076.66591004\n",
      "empirical sample complexity / H(M): 4.70354819707 \n",
      "\n",
      "H(M):  1578.91054253\n",
      "empirical sample complexity / H(M): 4.74646903555 \n",
      "\n",
      "H(M):  2179.01141861\n",
      "empirical sample complexity / H(M): 4.03006148797 \n",
      "\n",
      "H(M):  2877.20736974\n",
      "empirical sample complexity / H(M): 4.2545768959 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "numit = 40\n",
    "k = 1\n",
    "delta = 0.1\n",
    "\n",
    "for n in range(4,10):\n",
    "    pmodel = pairwise(n)\n",
    "    w = [ i/float(n) for i in range(n) ] #w = random.rand(n)+0.1\n",
    "    pmodel.generate_deterministic_BTL(w)\n",
    "    print(\"H(M): \", pmodel.topk_complexity(k))\n",
    "    alg = LUCB_ranking(pmodel,k)\n",
    "    su = 0\n",
    "    for i in range(numit):\n",
    "        alg.pairwise.ctr = 0\n",
    "        alg.rank(0.1)\n",
    "        su += alg.pairwise.ctr / alg.pairwise.topk_complexity() / numit \n",
    "    print(\"empirical sample complexity / H(M):\", su, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
